{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Top Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Bottom Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Index, Columns, and Data: df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill/Drop Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename Columns: df.rename(columns={'old_name': 'new_name'})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Columns: df.drop(columns=['column_name'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function: df['column'].apply(lambda x: function(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by and aggregate: df.groupby('column').agg({'column': 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot Tables: df.pivot_table(index='column1', values='column2', aggfunc='mean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Merge DataFrames: pd.merge(df1, df2, on='column')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate DataFrames: pd.concat([df1, df2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram: df['column'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot: df.boxplot(column=['column1', 'column2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter Plot: df.plot.scatter(x='col1', y='col2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line Plot: df.plot.line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar Chart: df['column'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Matrix: df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covariance Matrix: df.cov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value Counts: df['column'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique Values in Column: df['column'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Unique Values: df['column'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Indexing and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Column: df['column']\n",
    "# Select Multiple Columns: df[['col1', 'col2']]\n",
    "# Select Rows by Position: df.iloc[0:5]\n",
    "# Select Rows by Label: df.loc[0:5]\n",
    "# Conditional Selection: df[df['column'] > value]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Data Formatting and Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Data Types: df['column'].astype('type')\n",
    "# String Operations: df['column'].str.lower()\n",
    "# Datetime Conversion: pd.to_datetime(df['column'])\n",
    "# Setting Index: df.set_index('column')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Advanced Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lambda Functions: df.apply(lambda x: x + 1)\n",
    "# Pivot Longer/Wider Format: df.melt(id_vars=['col1'])\n",
    "# Stack/Unstack: df.stack(), df.unstack()\n",
    "# Cross Tabulations: pd.crosstab(df['col1'], df['col2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Handling Time Series Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Datetime Index: df.set_index(pd.to_datetime(df['date']))\n",
    "# Resampling Data: df.resample('M').mean()\n",
    "# Rolling Window Operations: df.rolling(window=5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. File to Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to CSV: df.to_csv('filename.csv')\n",
    "# Write to Excel: df.to_excel('filename.xlsx')\n",
    "# Write to SQL Database: df.to_sql('table_name', connection)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Data Exploration Techniques\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profile Report (with pandas-profiling): from pandas_profiling import\n",
    "# ProfileReport; ProfileReport(df)\n",
    "# Pairplot (with seaborn): import seaborn as sns; sns.pairplot(df)\n",
    "# Heatmap for Correlation (with seaborn): sns.heatmap(df.corr(), annot=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Advanced Data Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query Function: df.query('column > value')\n",
    "# Filtering with isin: df[df['column'].isin([value1, value2])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Memory Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reducing Memory Usage: df.memory_usage(deep=True)\n",
    "# Change Data Types to Save Memory: df['column'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. Multi-Index Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating MultiIndex: df.set_index(['col1', 'col2'])\n",
    "# Slicing on MultiIndex: df.loc[(slice('index1_start', 'index1_end'),\n",
    "# slice('index2_start', 'index2_end'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16. Data Merging Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outer Join: pd.merge(df1, df2, on='column', how='outer')\n",
    "# Inner Join: pd.merge(df1, df2, on='column', how='inner')\n",
    "# Left Join: pd.merge(df1, df2, on='column', how='left')\n",
    "# Right Join: pd.merge(df1, df2, on='column', how='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17. Dealing with Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding Duplicates: df.duplicated()\n",
    "# Removing Duplicates: df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18. Custom Operations with Apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Apply Functions: df.apply(lambda row:\n",
    "# custom_func(row['col1'], row['col2']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19. Handling Large Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunking Large Files: pd.read_csv('large_file.csv', chunksize=1000)\n",
    "# Iterating Through Data Chunks: for chunk in pd.read_csv('file.csv', chunksize=500): process(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20. Integration with Matplotlib for Custom Plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Plotting: import matplotlib.pyplot as plt; df.plot();\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "21. Specialized Data Types Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with Categorical Data: df['column'].astype('category')\n",
    "# Dealing with Sparse Data: pd.arrays.SparseArray(df['column'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22. Performance Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Swifter for Faster Apply: \n",
    "# import swifter;\n",
    "# df['column'].swifter.apply(lambda x: func(x))\n",
    "# Parallel Processing with Dask: import dask.dataframe as dd; ddf = dd.from_pandas(df, npartitions=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "23. Visualization Enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customize Plot Style: plt.style.use('ggplot')\n",
    "# Histogram with Bins Specification: df['column'].hist(bins=20)\n",
    "# Boxplot Grouped by Category: df.boxplot(column='num_column', by='cat_column')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "24. Advanced Grouping and Aggregation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by Multiple Columns: df.groupby(['col1', 'col2']).mean()\n",
    "# Aggregate with Multiple Functions: df.groupby('col').agg(['mean','sum'])\n",
    "# Transform Function: df.groupby('col').transform(lambda x: x - x.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "25. Time Series Specific Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Based Grouping: df.groupby(pd.Grouper(key='date_col', freq='M')).sum()\n",
    "# Shifting Series for Lag Analysis: df['column'].shift(1)\n",
    "# Resample Time Series Data: df.resample('M', on='date_col').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "26. Text Data Specific Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String Contains: df[df['column'].str.contains('substring')]\n",
    "# String Split: df['column'].str.split(' ', expand=True)\n",
    "# Regular Expression Extraction: df['column'].str.extract(r'(regex)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "27. Data Normalization and Standardization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-Max Normalization: (df['column'] - df['column'].min()) /(df['column'].max() - df['column'].min())\n",
    "# Z-Score Standardization: (df['column'] - df['column'].mean()) /df['column'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "28. Working with JSON and XML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading JSON: df = pd.read_json('filename.json')\n",
    "# Reading XML: df = pd.read_xml('filename.xml')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "29. Advanced File Handling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV with Specific Delimiter: df = pd.read_csv('filename.csv',delimiter=';')\n",
    "# Writing to JSON: df.to_json('filename.json')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "30. Dealing with Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate Missing Values: df['column'].interpolate()\n",
    "# Forward Fill Missing Values: df['column'].ffill()\n",
    "# Backward Fill Missing Values: df['column'].bfill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "31. Data Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wide to Long Format: pd.wide_to_long(df, ['col'], i='id_col', j='year')\n",
    "# Long to Wide Format: df.pivot(index='id_col', columns='year',values='col')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "32. Categorical Data Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Column to Categorical: df['column'] = df['column'].astype('category')\n",
    "# Order Categories: df['column'].cat.set_categories(['cat1', 'cat2'], ordered=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "33. Advanced Indexing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset Index: df.reset_index(drop=True)\n",
    "# Set Multiple Indexes: df.set_index(['col1', 'col2'])\n",
    "# MultiIndex Slicing: df.xs(key='value', level='level_name')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "34. Efficient Computations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use of eval() for Efficient Operations: df.eval('col1 + col2')\n",
    "# Query Method for Filtering: df.query('col1 < col2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "35. Integration with SciPy and StatsModels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression (with statsmodels): import statsmodels.api as sm; sm.OLS(y, X).fit()\n",
    "# Kurtosis and Skewness (with SciPy): from scipy.stats import kurtosis, skew; kurtosis(df['column']), skew(df['column'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "36. Handling Large Data Efficiently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dask Integration for Large Data: import dask.dataframe as dd; ddf = dd.from_pandas(df, npartitions=10)\n",
    "# Sampling Data for Quick Insights: df.sample(n=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "37. Advanced Data Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL-like Joins: pd.merge(df1, df2, how='left', on='col')\n",
    "# Concatenating Along a Different Axis: pd.concat([df1, df2],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "38. Profiling Data for Quick Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Pandas Profiling for Quick Analysis: from pandas_profiling\n",
    "# import ProfileReport; report = ProfileReport(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "39. Working with External Data Sources\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Data from HTML: dfs = pd.read_html('http://example.com')\n",
    "# Connecting to a SQL Database: from sqlalchemy import create_engine;\n",
    "# engine = create_engine('sqlite:///db.sqlite'); df =\n",
    "# pd.read_sql('SELECT * FROM table_name', engine)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "40. Data Quality Checks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assert Statement for Data Validation: assert\n",
    "# df.notnull().all().all(), \"There are missing values in the dataframe\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
